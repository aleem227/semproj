{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, TopK, util } from '@tensorflow/tfjs-core';\nimport { topKImplCPU } from '../kernel_utils/shared';\nimport { MergeProgram, SwapProgram } from '../top_k_gpu';\nimport { fill } from './Fill';\nimport { gatherV2 } from './GatherV2';\nimport { reshape } from './Reshape';\nimport { slice } from './Slice';\nfunction disposeIntermediateTensorInfoOrNull(backend, tensorInfo) {\n  if (tensorInfo !== null) {\n    backend.disposeIntermediateTensorInfo(tensorInfo);\n  }\n}\nfunction roundUpToPow2(num) {\n  let pow2 = 1;\n  while (pow2 < num) {\n    pow2 *= 2;\n  }\n  return pow2;\n}\n// Based on Algorithm 2 of Bitonic Top K, ref:\n// https://anilshanbhag.in/static/papers/gputopk_sigmod18.pdf\nexport function topK(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    k,\n    sorted\n  } = attrs;\n  // Empirically determined constant used to determine last dim threshold for\n  // handing off execution to the CPU.\n  const TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD = env().getNumber('TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD');\n  // Empirically determined constant used to determine k threshold for handing\n  // off execution to the CPU.\n  const TOPK_K_CPU_HANDOFF_THRESHOLD = env().getNumber('TOPK_K_CPU_HANDOFF_THRESHOLD');\n  const xShape = x.shape;\n  const lastDim = xShape[xShape.length - 1];\n  if (backend.shouldExecuteOnCPU([x]) || lastDim < TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD || k > TOPK_K_CPU_HANDOFF_THRESHOLD) {\n    const xVals = backend.readSync(x.dataId);\n    const [allTopKVals, allTopKIndices] = topKImplCPU(xVals, xShape, x.dtype, k, sorted);\n    return [backend.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values), backend.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)];\n  }\n  if (k === 0) {\n    xShape[xShape.length - 1] = 0;\n    return [backend.makeTensorInfo(xShape, x.dtype, []), backend.makeTensorInfo(xShape, 'int32', [])];\n  }\n  if (lastDim === 1 /* firstPass */) {\n    return [x, fill({\n      attrs: {\n        shape: xShape,\n        dtype: 'int32',\n        value: 0\n      },\n      backend\n    })];\n  }\n  // Eagerly unpack x input since it is passed in to all the shaders which\n  // require unpacked inputs.\n  const xtexData = backend.texData.get(x.dataId);\n  const xIsPacked = xtexData !== null && xtexData.isPacked;\n  const xUnPacked = xIsPacked ? backend.unpackTensor(x) : x;\n  // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n  const xSize = util.sizeFromShape(xShape);\n  const batch = xSize / lastDim;\n  const x2D = reshape({\n    inputs: {\n      x: xUnPacked\n    },\n    attrs: {\n      shape: [batch, lastDim]\n    },\n    backend\n  });\n  if (xIsPacked) {\n    disposeIntermediateTensorInfoOrNull(backend, xUnPacked);\n  }\n  const kPow2 = roundUpToPow2(k);\n  const lastDimPow2 = roundUpToPow2(lastDim);\n  // Only the indices containing the top K are kept at every step to reduce\n  // number of outputs in the GPU algorithms, so once the final set of indices\n  // is computed then gather is used to grab the corresponding values\n  // from the original input.\n  let indices = null;\n  // GPU algorithm always takes in an indices input but this input is not used\n  // on the first run of a GPU algorithm, therefore if indices is null we simply\n  // pass in x2D instead of it but the value will not actually be used\n  const getInputs = () => indices === null ? [x2D, x2D] : [x2D, indices];\n  const runSwap = (dir, inc, shape) => {\n    const inputs = getInputs();\n    const program = new SwapProgram(shape);\n    const fistPass = indices === null ? 1 : 0;\n    const customValues = [[lastDim], [fistPass], [Number.NEGATIVE_INFINITY], [dir], [inc]];\n    const prevIndices = indices;\n    indices = backend.runWebGLProgram(program, inputs, 'int32', customValues);\n    disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n  };\n  // Step 1: local sort\n  for (let len = 1; len < kPow2; len *= 2) {\n    const dir = len * 2;\n    for (let inc = len; inc >= 1; inc /= 2) {\n      runSwap(dir, inc, [batch, lastDimPow2]);\n    }\n  }\n  // Step 2: merge\n  for (let indicesSize = lastDimPow2; indicesSize > kPow2; indicesSize /= 2) {\n    const inputs = getInputs();\n    const mergeProgram = new MergeProgram([batch, indicesSize / 2]);\n    const firstPass = indices === null ? 1 : 0;\n    const customValues = [[lastDim], [firstPass], [kPow2]];\n    const prevIndices = indices;\n    indices = backend.runWebGLProgram(mergeProgram, inputs, 'int32', customValues);\n    disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n    // Step 3: rebuild\n    const len = kPow2 / 2;\n    const dir = len * 2;\n    for (let inc = len; inc >= 1; inc /= 2) {\n      runSwap(dir, inc, indices.shape);\n    }\n  }\n  // Keep only the requested top K results instead of kPow2\n  let prevIndices = indices;\n  indices = slice({\n    inputs: {\n      x: indices\n    },\n    backend,\n    attrs: {\n      begin: 0,\n      size: [batch, k]\n    }\n  });\n  disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n  // Gather values on last dimension\n  let values = gatherV2({\n    inputs: {\n      x: x2D,\n      indices\n    },\n    backend,\n    attrs: {\n      axis: 1,\n      batchDims: 1\n    }\n  });\n  disposeIntermediateTensorInfoOrNull(backend, x2D);\n  // Reshape back to the original input shape, except that the last\n  // dimension is k.\n  const newShape = xShape.slice(0, -1);\n  newShape.push(k);\n  prevIndices = indices;\n  indices = reshape({\n    inputs: {\n      x: indices\n    },\n    attrs: {\n      shape: newShape\n    },\n    backend\n  });\n  disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n  const prevValues = values;\n  values = reshape({\n    inputs: {\n      x: values\n    },\n    attrs: {\n      shape: newShape\n    },\n    backend\n  });\n  disposeIntermediateTensorInfoOrNull(backend, prevValues);\n  return [values, indices];\n}\nexport const topKConfig = {\n  kernelName: TopK,\n  backendName: 'webgl',\n  kernelFunc: topK\n};","map":null,"metadata":{},"sourceType":"module"}