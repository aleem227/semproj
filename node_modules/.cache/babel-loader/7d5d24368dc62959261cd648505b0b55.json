{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, FusedConv2D, util } from '@tensorflow/tfjs-core';\nimport { Conv2DProgram } from '../conv_gpu';\nimport { Conv2DPackedProgram } from '../conv_packed_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { conv2dByMatMul, conv2dWithIm2Row } from './Conv2D_impl';\nimport { reshape } from './Reshape';\nexport function fusedConv2d(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x,\n    filter,\n    bias,\n    preluActivationWeights\n  } = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false /* depthwise */, $dataFormat);\n  let out;\n  const intermediates = [];\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const hasLeakyreluAlpha = activation === 'leakyrelu';\n  const prepareInputs = () => {\n    const inputs = [x, filter];\n    // If the input is a 1-D tensor, align it with the channels.\n    //\n    // For fusedConv2d, the inputs (x, W, bias, preluActivationWeights) are\n    // supposed to be aligned with the dataFormat. The 4-D tensor inputs or\n    // scalar inputs are originally aligned, but the 1-D tensor inputs are\n    // supposed to be aligned with the channels (only bias and PReLU activation\n    // weights could be a 1-D tensor).\n    const alignInputWithDataFormat = (input, dataFormat) => {\n      if (dataFormat === 'NCHW' && input.shape.length === 1 && input.shape[0] !== 1) {\n        const alignedInput = reshape({\n          inputs: {\n            x: input\n          },\n          backend,\n          attrs: {\n            shape: [input.shape[0], 1, 1]\n          }\n        });\n        intermediates.push(alignedInput);\n        return alignedInput;\n      }\n      return input;\n    };\n    if (hasBias) {\n      inputs.push(alignInputWithDataFormat(bias, dataFormat));\n    }\n    if (hasPreluActivationWeights) {\n      inputs.push(alignInputWithDataFormat(preluActivationWeights, dataFormat));\n    }\n    if (hasLeakyreluAlpha) {\n      const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n      inputs.push($leakyreluAlpha);\n      intermediates.push($leakyreluAlpha);\n    }\n    return inputs;\n  };\n  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n    out = conv2dByMatMul({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else if (convInfo.strideWidth <= 2 && $dataFormat === 'channelsLast' && env().getBool('WEBGL_EXP_CONV')) {\n    const fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n    const program = new Conv2DPackedProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    const customValues = [[convInfo.padInfo.top, convInfo.padInfo.left], [convInfo.strideHeight, convInfo.strideWidth], [convInfo.dilationHeight, convInfo.dilationWidth], [convInfo.inHeight, convInfo.inWidth]];\n    const inputs = prepareInputs();\n    out = backend.runWebGLProgram(program, inputs, 'float32', customValues);\n  } else if (env().getBool('WEBGL_CONV_IM2COL')) {\n    out = conv2dWithIm2Row({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else {\n    const fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;\n    const program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    const inputs = prepareInputs();\n    out = backend.runWebGLProgram(program, inputs, 'float32');\n  }\n  const outReshaped = reshape({\n    inputs: {\n      x: out\n    },\n    backend,\n    attrs: {\n      shape: convInfo.outShape\n    }\n  });\n  intermediates.push(out);\n  intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n  return outReshaped;\n}\nexport const fusedConv2DConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'webgl',\n  kernelFunc: fusedConv2d\n};","map":null,"metadata":{},"sourceType":"module"}