{"ast":null,"code":"/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Import webgl flags.\nimport './flags_webgl';\nimport { backend_util, buffer, DataStorage, engine, env, kernel_impls, KernelBackend, nextFrame, scalar, tidy, util } from '@tensorflow/tfjs-core';\nimport { getWebGLContext } from './canvas_util';\nimport { DecodeMatrixProgram } from './decode_matrix_gpu';\nimport { DecodeMatrixPackedProgram } from './decode_matrix_packed_gpu';\nimport { EncodeFloatProgram } from './encode_float_gpu';\nimport { EncodeFloatPackedProgram } from './encode_float_packed_gpu';\nimport { EncodeMatrixProgram } from './encode_matrix_gpu';\nimport { EncodeMatrixPackedProgram } from './encode_matrix_packed_gpu';\nimport { GPGPUContext } from './gpgpu_context';\nimport * as gpgpu_math from './gpgpu_math';\nimport { getUniformLocations } from './gpgpu_math';\nimport { simpleAbsImplCPU } from './kernel_utils/shared';\nimport { PackProgram } from './pack_gpu';\nimport { ReshapePackedProgram } from './reshape_packed_gpu';\nimport * as tex_util from './tex_util';\nimport { TextureUsage } from './tex_util';\nimport { TextureManager } from './texture_manager';\nimport * as unary_op from './unaryop_gpu';\nimport { UnaryOpProgram } from './unaryop_gpu';\nimport { UnaryOpPackedProgram } from './unaryop_packed_gpu';\nimport { UnpackProgram } from './unpack_gpu';\nimport * as webgl_util from './webgl_util';\nconst whereImpl = kernel_impls.whereImpl;\nexport const EPSILON_FLOAT32 = 1e-7;\nexport const EPSILON_FLOAT16 = 1e-4;\nconst binaryCaches = {};\nexport function getBinaryCache(webGLVersion) {\n  if (webGLVersion in binaryCaches) {\n    return binaryCaches[webGLVersion];\n  }\n  binaryCaches[webGLVersion] = {};\n  return binaryCaches[webGLVersion];\n}\n// Empirically determined constant used to determine size threshold for handing\n// off execution to the CPU.\nconst CPU_HANDOFF_SIZE_THRESHOLD = env().getNumber('CPU_HANDOFF_SIZE_THRESHOLD');\n// Empirically determined constant used to decide the number of MB on GPU\n// before we warn about high memory use. The MB are this constant * screen area\n// * dpi / 1024 / 1024.\nconst BEFORE_PAGING_CONSTANT = 600;\nfunction numMBBeforeWarning() {\n  if (env().global.screen == null) {\n    return 1024; // 1 GB.\n  }\n  return env().global.screen.height * env().global.screen.width * window.devicePixelRatio * BEFORE_PAGING_CONSTANT / 1024 / 1024;\n}\nclass MathBackendWebGL extends KernelBackend {\n  nextDataId() {\n    return MathBackendWebGL.nextDataId++;\n  }\n  constructor(gpuResource) {\n    super();\n    // Maps data ids that have a pending read operation, to list of subscribers.\n    this.pendingRead = new WeakMap();\n    // List of data ids that are scheduled for disposal, but are waiting on a\n    // pending read operation.\n    this.pendingDisposal = new WeakSet();\n    // Used to count the number of 'shallow' sliced tensors that point to the\n    // same data id.\n    this.dataRefCount = new WeakMap();\n    this.numBytesInGPU = 0;\n    // Accumulated time spent (including blocking) in uploading data to webgl.\n    this.uploadWaitMs = 0;\n    // Accumulated time spent (including blocking in downloading data from webgl.\n    this.downloadWaitMs = 0;\n    // record the last manual GL Flush time.\n    this.lastGlFlushTime = 0;\n    this.warnedAboutMemory = false;\n    this.pendingDeletes = 0;\n    this.disposed = false;\n    if (!env().getBool('HAS_WEBGL')) {\n      throw new Error('WebGL is not supported on this device');\n    }\n    let newGPGPU;\n    if (gpuResource != null) {\n      if (gpuResource instanceof GPGPUContext) {\n        newGPGPU = gpuResource;\n      } else {\n        const gl = getWebGLContext(env().getNumber('WEBGL_VERSION'), gpuResource);\n        newGPGPU = new GPGPUContext(gl);\n      }\n      this.binaryCache = {};\n      this.gpgpuCreatedLocally = false;\n    } else {\n      const gl = getWebGLContext(env().getNumber('WEBGL_VERSION'));\n      newGPGPU = new GPGPUContext(gl);\n      this.binaryCache = getBinaryCache(env().getNumber('WEBGL_VERSION'));\n      this.gpgpuCreatedLocally = true;\n    }\n    this.gpgpu = newGPGPU;\n    this.canvas = this.gpgpu.gl.canvas;\n    this.textureManager = new TextureManager(this.gpgpu);\n    this.numMBBeforeWarning = numMBBeforeWarning();\n    this.texData = new DataStorage(this, engine());\n  }\n  numDataIds() {\n    return this.texData.numDataIds() - this.pendingDeletes;\n  }\n  // Writes a new entry to the data store with a WebGL texture, and registers it\n  // to the texture manager.\n  writeTexture(texture, shape, dtype, texHeight, texWidth, channels) {\n    // Temporarily create an tensor info to make the texture compatible with\n    // the runWebGLProgram's input.\n    const input = this.makeTensorInfo(shape, dtype);\n    const inData = this.texData.get(input.dataId);\n    // Even though the input texture could be unpacked or dense packed, it is\n    // always considered as unpacked for EncodeMatrixProgram.\n    inData.isPacked = false;\n    // Bind texture to the input tensor.\n    inData.texture = {\n      texture,\n      texShape: [texHeight, texWidth]\n    };\n    inData.texShape = [texHeight, texWidth];\n    const shapeAs3D = webgl_util.getShapeAs3D(shape);\n    const program = new EncodeMatrixProgram(shapeAs3D, false /* isByteArray */, channels);\n    const output = this.runWebGLProgram(program, [input], dtype, [[texHeight, texWidth]]);\n    output.shape = shape;\n    // Unbind the texture from the input tensor to avoid the texture being\n    // released.\n    inData.texture = null;\n    this.disposeIntermediateTensorInfo(input);\n    return output.dataId;\n  }\n  write(values, shape, dtype) {\n    if (env().getBool('WEBGL_CHECK_NUMERICAL_PROBLEMS') || env().getBool('DEBUG')) {\n      this.checkNumericalProblems(values);\n    }\n    if (dtype === 'complex64' && values != null) {\n      throw new Error(`Cannot write to a complex64 dtype. ` + `Please use tf.complex(real, imag).`);\n    }\n    const dataId = {\n      id: this.nextDataId()\n    };\n    this.texData.set(dataId, {\n      shape,\n      dtype,\n      values,\n      usage: TextureUsage.UPLOAD,\n      refCount: 1\n    });\n    return dataId;\n  }\n  /** Return refCount of a `TensorData`. */\n  refCount(dataId) {\n    if (this.texData.has(dataId)) {\n      const tensorData = this.texData.get(dataId);\n      return tensorData.refCount;\n    }\n    return 0;\n  }\n  /** Increase refCount of a `TextureData`. */\n  incRef(dataId) {\n    const texData = this.texData.get(dataId);\n    texData.refCount++;\n  }\n  /** Decrease refCount of a `TextureData`. */\n  decRef(dataId) {\n    if (this.texData.has(dataId)) {\n      const texData = this.texData.get(dataId);\n      texData.refCount--;\n    }\n  }\n  move(dataId, values, shape, dtype, refCount) {\n    if (env().getBool('DEBUG')) {\n      this.checkNumericalProblems(values);\n    }\n    if (dtype === 'complex64') {\n      throw new Error(`Cannot write to a complex64 dtype. ` + `Please use tf.complex(real, imag).`);\n    }\n    this.texData.set(dataId, {\n      shape,\n      dtype,\n      values,\n      usage: TextureUsage.UPLOAD,\n      refCount\n    });\n  }\n  disposeIntermediateTensorInfo(tensorInfo) {\n    this.disposeData(tensorInfo.dataId);\n  }\n  readSync(dataId) {\n    const texData = this.texData.get(dataId);\n    const {\n      values,\n      dtype,\n      complexTensorInfos,\n      slice,\n      shape,\n      isPacked\n    } = texData;\n    // The presence of `slice` indicates this tensor is a shallow slice of a\n    // different tensor, and is using that original tensor's texture. Run\n    // `clone` in order to copy that texture and read from it.\n    if (slice != null) {\n      let program;\n      if (isPacked) {\n        program = new UnaryOpPackedProgram(shape, unary_op.CLONE);\n      } else {\n        program = new UnaryOpProgram(shape, unary_op.CLONE);\n      }\n      const res = this.runWebGLProgram(program, [{\n        dataId,\n        shape,\n        dtype\n      }], dtype);\n      const data = this.readSync(res.dataId);\n      this.disposeIntermediateTensorInfo(res);\n      return data;\n    }\n    if (values != null) {\n      return this.convertAndCacheOnCPU(dataId);\n    }\n    if (dtype === 'string') {\n      return values;\n    }\n    const shouldTimeProgram = this.activeTimers != null;\n    let start;\n    if (shouldTimeProgram) {\n      start = util.now();\n    }\n    let result;\n    if (dtype === 'complex64') {\n      const realValues = this.readSync(complexTensorInfos.real.dataId);\n      const imagValues = this.readSync(complexTensorInfos.imag.dataId);\n      result = backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    } else {\n      result = this.getValuesFromTexture(dataId);\n    }\n    if (shouldTimeProgram) {\n      this.downloadWaitMs += util.now() - start;\n    }\n    return this.convertAndCacheOnCPU(dataId, result);\n  }\n  async read(dataId) {\n    if (this.pendingRead.has(dataId)) {\n      const subscribers = this.pendingRead.get(dataId);\n      return new Promise(resolve => subscribers.push(resolve));\n    }\n    const texData = this.texData.get(dataId);\n    const {\n      values,\n      shape,\n      slice,\n      dtype,\n      complexTensorInfos,\n      isPacked\n    } = texData;\n    // The presence of `slice` indicates this tensor is a shallow slice of a\n    // different tensor, and is using that original tensor's texture. Run\n    // `clone` in order to copy that texture and read from it.\n    if (slice != null) {\n      let program;\n      if (isPacked) {\n        program = new UnaryOpPackedProgram(shape, unary_op.CLONE);\n      } else {\n        program = new UnaryOpProgram(shape, unary_op.CLONE);\n      }\n      const res = this.runWebGLProgram(program, [{\n        dataId,\n        shape,\n        dtype\n      }], dtype);\n      const data = this.read(res.dataId);\n      this.disposeIntermediateTensorInfo(res);\n      return data;\n    }\n    if (values != null) {\n      return this.convertAndCacheOnCPU(dataId);\n    }\n    if (env().getBool('DEBUG')) {\n      // getBool('WEBGL_DOWNLOAD_FLOAT_ENABLED') caused a blocking GPU call.\n      // For performance reason, only check it for debugging. In production,\n      // it doesn't handle this use case anyway, so behavior is not changed.\n      if (!env().getBool('WEBGL_DOWNLOAD_FLOAT_ENABLED') && env().getNumber('WEBGL_VERSION') === 2) {\n        throw new Error(`tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and ` + `WEBGL_VERSION=2 not yet supported.`);\n      }\n    }\n    let buffer = null;\n    let tmpDownloadTarget;\n    if (dtype !== 'complex64' && env().get('WEBGL_BUFFER_SUPPORTED')) {\n      // Possibly copy the texture into a buffer before inserting a fence.\n      tmpDownloadTarget = this.decode(dataId);\n      const tmpData = this.texData.get(tmpDownloadTarget.dataId);\n      buffer = this.gpgpu.createBufferFromTexture(tmpData.texture.texture, ...tex_util.getDenseTexShape(shape));\n    }\n    this.pendingRead.set(dataId, []);\n    if (dtype !== 'complex64') {\n      // Create a fence and wait for it to resolve.\n      await this.gpgpu.createAndWaitForFence();\n    }\n    // Download the values from the GPU.\n    let vals;\n    if (dtype === 'complex64') {\n      const ps = await Promise.all([this.read(complexTensorInfos.real.dataId), this.read(complexTensorInfos.imag.dataId)]);\n      const realValues = ps[0];\n      const imagValues = ps[1];\n      vals = backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    } else if (buffer == null) {\n      vals = this.getValuesFromTexture(dataId);\n    } else {\n      const size = util.sizeFromShape(shape);\n      vals = this.gpgpu.downloadFloat32MatrixFromBuffer(buffer, size);\n    }\n    if (tmpDownloadTarget != null) {\n      this.disposeIntermediateTensorInfo(tmpDownloadTarget);\n    }\n    if (buffer != null) {\n      const gl = this.gpgpu.gl;\n      webgl_util.callAndCheck(gl, () => gl.deleteBuffer(buffer));\n    }\n    const dTypeVals = this.convertAndCacheOnCPU(dataId, vals);\n    const subscribers = this.pendingRead.get(dataId);\n    this.pendingRead.delete(dataId);\n    // Notify all pending reads.\n    subscribers.forEach(resolve => resolve(dTypeVals));\n    if (this.pendingDisposal.has(dataId)) {\n      this.pendingDisposal.delete(dataId);\n      if (this.disposeData(dataId)) {\n        engine().removeDataId(dataId, this);\n      }\n      this.pendingDeletes--;\n    }\n    return dTypeVals;\n  }\n  /**\n   * Read tensor to a new texture that is densely packed for ease of use.\n   * @param dataId The source tensor.\n   * @param options\n   *     customTexShape: Optional. If set, will use the user defined texture\n   *     shape to create the texture.\n   */\n  readToGPU(dataId, options = {}) {\n    const texData = this.texData.get(dataId);\n    const {\n      values,\n      shape,\n      slice,\n      dtype,\n      isPacked,\n      texture\n    } = texData;\n    if (dtype === 'complex64') {\n      throw new Error('Does not support reading texture for complex64 dtype.');\n    }\n    // The presence of `slice` indicates this tensor is a shallow slice of a\n    // different tensor, and is using that original tensor's texture. Run\n    // `clone` in order to copy that texture and read from it.\n    if (slice != null) {\n      let program;\n      if (isPacked) {\n        program = new UnaryOpPackedProgram(shape, unary_op.CLONE);\n      } else {\n        program = new UnaryOpProgram(shape, unary_op.CLONE);\n      }\n      const res = this.runWebGLProgram(program, [{\n        dataId,\n        shape,\n        dtype\n      }], dtype);\n      const gpuResouorce = this.readToGPU(res, options);\n      this.disposeIntermediateTensorInfo(res);\n      return gpuResouorce;\n    }\n    if (texture == null) {\n      if (values != null) {\n        throw new Error('Data is not on GPU but on CPU.');\n      } else {\n        throw new Error('There is no data on GPU or CPU.');\n      }\n    }\n    // Decode the texture so that it is stored densely (using four channels).\n    const tmpTarget = this.decode(dataId, options.customTexShape);\n    // Make engine track this tensor, so that we can dispose it later.\n    const tensorRef = engine().makeTensorFromTensorInfo(tmpTarget);\n    const tmpData = this.texData.get(tmpTarget.dataId);\n    return Object.assign({\n      tensorRef\n    }, tmpData.texture);\n  }\n  bufferSync(t) {\n    const data = this.readSync(t.dataId);\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        const strings = data.map(d => util.decodeString(d));\n        return buffer(t.shape, t.dtype, strings);\n      } catch (_a) {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape, t.dtype, data);\n  }\n  checkNumericalProblems(values) {\n    if (values == null) {\n      return;\n    }\n    for (let i = 0; i < values.length; i++) {\n      const num = values[i];\n      if (!webgl_util.canBeRepresented(num)) {\n        if (env().getBool('WEBGL_RENDER_FLOAT32_CAPABLE')) {\n          throw Error(`The value ${num} cannot be represented with your ` + `current settings. Consider enabling float32 rendering: ` + `'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);\n        }\n        throw Error(`The value ${num} cannot be represented on this device.`);\n      }\n    }\n  }\n  getValuesFromTexture(dataId) {\n    const {\n      shape,\n      dtype,\n      isPacked\n    } = this.texData.get(dataId);\n    const size = util.sizeFromShape(shape);\n    if (env().getBool('WEBGL_DOWNLOAD_FLOAT_ENABLED')) {\n      const tmpTarget = this.decode(dataId);\n      const tmpData = this.texData.get(tmpTarget.dataId);\n      const vals = this.gpgpu.downloadMatrixFromPackedTexture(tmpData.texture.texture, ...tex_util.getDenseTexShape(shape)).subarray(0, size);\n      this.disposeIntermediateTensorInfo(tmpTarget);\n      return vals;\n    }\n    const shouldUsePackedProgram = env().getBool('WEBGL_PACK') && isPacked === true;\n    const outputShape = shouldUsePackedProgram ? webgl_util.getShapeAs3D(shape) : shape;\n    const program = shouldUsePackedProgram ? new EncodeFloatPackedProgram(outputShape) : new EncodeFloatProgram(outputShape);\n    const output = this.runWebGLProgram(program, [{\n      shape: outputShape,\n      dtype,\n      dataId\n    }], 'float32');\n    const tmpData = this.texData.get(output.dataId);\n    const vals = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture.texture, tmpData.texShape[0], tmpData.texShape[1]).subarray(0, size);\n    this.disposeIntermediateTensorInfo(output);\n    return vals;\n  }\n  timerAvailable() {\n    return env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0;\n  }\n  time(f) {\n    const oldActiveTimers = this.activeTimers;\n    const newActiveTimers = [];\n    let outerMostTime = false;\n    if (this.programTimersStack == null) {\n      this.programTimersStack = newActiveTimers;\n      outerMostTime = true;\n    } else {\n      this.activeTimers.push(newActiveTimers);\n    }\n    this.activeTimers = newActiveTimers;\n    f();\n    // needing to split these up because util.flatten only accepts certain types\n    const flattenedActiveTimerQueries = util.flatten(this.activeTimers.map(d => d.query)).filter(d => d != null);\n    const flattenedActiveTimerNames = util.flatten(this.activeTimers.map(d => d.name)).filter(d => d != null);\n    this.activeTimers = oldActiveTimers;\n    if (outerMostTime) {\n      this.programTimersStack = null;\n    }\n    const res = {\n      uploadWaitMs: this.uploadWaitMs,\n      downloadWaitMs: this.downloadWaitMs,\n      kernelMs: null,\n      wallMs: null // will be filled by the engine\n    };\n    return (async () => {\n      if (env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0) {\n        const kernelMs = await Promise.all(flattenedActiveTimerQueries);\n        res['kernelMs'] = util.sum(kernelMs);\n        res['getExtraProfileInfo'] = () => kernelMs.map((d, i) => ({\n          name: flattenedActiveTimerNames[i],\n          ms: d\n        })).map(d => `${d.name}: ${d.ms}`).join(', ');\n      } else {\n        res['kernelMs'] = {\n          error: 'WebGL query timers are not supported in this environment.'\n        };\n      }\n      this.uploadWaitMs = 0;\n      this.downloadWaitMs = 0;\n      return res;\n    })();\n  }\n  memory() {\n    return {\n      unreliable: false,\n      numBytesInGPU: this.numBytesInGPU,\n      numBytesInGPUAllocated: this.textureManager.numBytesAllocated,\n      numBytesInGPUFree: this.textureManager.numBytesFree\n    };\n  }\n  startTimer() {\n    if (env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0) {\n      return this.gpgpu.beginQuery();\n    }\n    return {\n      startMs: util.now(),\n      endMs: null\n    };\n  }\n  endTimer(query) {\n    if (env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0) {\n      this.gpgpu.endQuery();\n      return query;\n    }\n    query.endMs = util.now();\n    return query;\n  }\n  async getQueryTime(query) {\n    if (env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0) {\n      return this.gpgpu.waitForQueryAndGetTime(query);\n    }\n    const timerQuery = query;\n    return timerQuery.endMs - timerQuery.startMs;\n  }\n  /**\n   * Decrease the RefCount on the dataId and dispose the memory if the dataId\n   * has 0 refCount. If there are pending read on the data, the disposal would\n   * added to the pending delete queue. Return true if the dataId is removed\n   * from backend or the backend does not contain the dataId, false if the\n   * dataId is not removed. Memory may or may not be released even when dataId\n   * is removed, which also depends on dataRefCount, see `releaseGPU`.\n   * @param dataId\n   * @oaram force Optional, remove the data regardless of refCount\n   */\n  disposeData(dataId, force = false) {\n    if (this.pendingDisposal.has(dataId)) {\n      return false;\n    }\n    // No-op if already disposed.\n    if (!this.texData.has(dataId)) {\n      return true;\n    }\n    // if force flag is set, change refCount to 0, this would ensure disposal\n    // when added to the pendingDisposal queue. Memory may or may not be\n    // released, which also depends on dataRefCount, see `releaseGPU`.\n    if (force) {\n      this.texData.get(dataId).refCount = 0;\n    } else {\n      this.texData.get(dataId).refCount--;\n    }\n    if (!force && this.texData.get(dataId).refCount > 0) {\n      return false;\n    }\n    if (this.pendingRead.has(dataId)) {\n      this.pendingDisposal.add(dataId);\n      this.pendingDeletes++;\n      return false;\n    }\n    this.releaseGPUData(dataId);\n    const {\n      complexTensorInfos\n    } = this.texData.get(dataId);\n    if (complexTensorInfos != null) {\n      this.disposeData(complexTensorInfos.real.dataId, force);\n      this.disposeData(complexTensorInfos.imag.dataId, force);\n    }\n    this.texData.delete(dataId);\n    return true;\n  }\n  releaseGPUData(dataId) {\n    const {\n      texture,\n      dtype,\n      texShape,\n      usage,\n      isPacked,\n      slice\n    } = this.texData.get(dataId);\n    const key = slice && slice.origDataId || dataId;\n    const refCount = this.dataRefCount.get(key);\n    if (refCount > 1) {\n      this.dataRefCount.set(key, refCount - 1);\n    } else {\n      this.dataRefCount.delete(key);\n      if (texture != null) {\n        this.numBytesInGPU -= this.computeBytes(texShape, dtype);\n        this.textureManager.releaseTexture(texture, texShape, usage, isPacked);\n      }\n    }\n    const texData = this.texData.get(dataId);\n    texData.texture = null;\n    texData.texShape = null;\n    texData.isPacked = false;\n    texData.slice = null;\n  }\n  getTexture(dataId) {\n    this.uploadToGPU(dataId);\n    return this.texData.get(dataId).texture.texture;\n  }\n  /**\n   * Returns internal information for the specific data bucket. Used in unit\n   * tests.\n   */\n  getDataInfo(dataId) {\n    return this.texData.get(dataId);\n  }\n  /*\n  Tests whether all the inputs to an op are small and on the CPU. This heuristic\n  determines when it would be faster to execute a kernel on the CPU. WebGL\n  kernels opt into running this check and forwarding when appropriate.\n  TODO(https://github.com/tensorflow/tfjs/issues/872): Develop a more\n  sustainable strategy for optimizing backend execution of ops.\n   */\n  shouldExecuteOnCPU(inputs, sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD) {\n    return env().getBool('WEBGL_CPU_FORWARD') && inputs.every(input => this.texData.get(input.dataId).texture == null && util.sizeFromShape(input.shape) < sizeThreshold);\n  }\n  getGPGPUContext() {\n    return this.gpgpu;\n  }\n  where(condition) {\n    backend_util.warn('tf.where() in webgl locks the UI thread. ' + 'Call tf.whereAsync() instead');\n    const condVals = condition.dataSync();\n    return whereImpl(condition.shape, condVals);\n  }\n  packedUnaryOp(x, op, dtype) {\n    const program = new UnaryOpPackedProgram(x.shape, op);\n    const outInfo = this.compileAndRun(program, [x], dtype);\n    return engine().makeTensorFromTensorInfo(outInfo);\n  }\n  // TODO(msoulanille) remove this once the backend has been modularized\n  // a copy is needed here to break a circular dependency.\n  // Also remove the op from unary_op.\n  abs(x) {\n    // TODO: handle cases when x is complex.\n    if (this.shouldExecuteOnCPU([x]) && x.dtype !== 'complex64') {\n      const outValues = simpleAbsImplCPU(this.texData.get(x.dataId).values);\n      return this.makeOutput(x.shape, x.dtype, outValues);\n    }\n    if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n      return this.packedUnaryOp(x, unary_op.ABS, x.dtype);\n    }\n    const program = new UnaryOpProgram(x.shape, unary_op.ABS);\n    const outInfo = this.compileAndRun(program, [x]);\n    return engine().makeTensorFromTensorInfo(outInfo);\n  }\n  makeTensorInfo(shape, dtype, values) {\n    let dataId;\n    if (dtype === 'string' && values != null && values.length > 0 && util.isString(values[0])) {\n      const encodedValues = values.map(d => util.encodeString(d));\n      dataId = this.write(encodedValues, shape, dtype);\n    } else {\n      dataId = this.write(values, shape, dtype);\n    }\n    this.texData.get(dataId).usage = null;\n    return {\n      dataId,\n      shape,\n      dtype\n    };\n  }\n  makeOutput(shape, dtype, values) {\n    return engine().makeTensorFromTensorInfo(this.makeTensorInfo(shape, dtype, values), this);\n  }\n  unpackTensor(input) {\n    const program = new UnpackProgram(input.shape);\n    return this.runWebGLProgram(program, [input], input.dtype);\n  }\n  packTensor(input) {\n    const program = new PackProgram(input.shape);\n    const preventEagerUnpackingOutput = true;\n    return this.runWebGLProgram(program, [input], input.dtype, null /* customUniformValues */, preventEagerUnpackingOutput);\n  }\n  packedReshape(input, afterShape) {\n    const input3DShape = [webgl_util.getBatchDim(input.shape), ...webgl_util.getRowsCols(input.shape)];\n    const input3D = {\n      dtype: input.dtype,\n      shape: input3DShape,\n      dataId: input.dataId\n    };\n    const afterShapeAs3D = [webgl_util.getBatchDim(afterShape), ...webgl_util.getRowsCols(afterShape)];\n    const program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);\n    const preventEagerUnpackingOfOutput = true;\n    const customValues = [input3DShape];\n    const output = this.runWebGLProgram(program, [input3D], input.dtype, customValues, preventEagerUnpackingOfOutput);\n    return {\n      dataId: output.dataId,\n      shape: afterShape,\n      dtype: output.dtype\n    };\n  }\n  decode(dataId, customTexShape) {\n    const texData = this.texData.get(dataId);\n    const {\n      isPacked,\n      shape,\n      dtype\n    } = texData;\n    if (customTexShape != null) {\n      const size = util.sizeFromShape(shape);\n      const texSize = customTexShape[0] * customTexShape[1] * 4;\n      util.assert(size <= texSize, () => 'customTexShape is too small. ' + 'Row * Column * 4 should be equal or larger than the ' + 'size of the tensor data.');\n    }\n    const shapeAs3D = webgl_util.getShapeAs3D(shape);\n    let program;\n    if (isPacked) {\n      program = new DecodeMatrixPackedProgram(shapeAs3D);\n    } else {\n      program = new DecodeMatrixProgram(shapeAs3D);\n    }\n    const preventEagerUnpackingOfOutput = true;\n    const customValues = [customTexShape != null ? customTexShape : tex_util.getDenseTexShape(shapeAs3D)];\n    const out = this.runWebGLProgram(program, [{\n      shape: shapeAs3D,\n      dtype,\n      dataId\n    }], dtype, customValues, preventEagerUnpackingOfOutput, customTexShape);\n    return {\n      dtype,\n      shape,\n      dataId: out.dataId\n    };\n  }\n  runWebGLProgram(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput = false, customTexShape) {\n    const output = this.makeTensorInfo(program.outputShape, outputDtype);\n    const outData = this.texData.get(output.dataId);\n    if (program.packedOutput) {\n      outData.isPacked = true;\n    }\n    if (program.outPackingScheme === tex_util.PackingScheme.DENSE) {\n      const texelShape = customTexShape != null ? customTexShape : tex_util.getDenseTexShape(program.outputShape);\n      // For a densely packed output, we explicitly set texShape\n      // so it doesn't get assigned later according to our typical packing\n      // scheme wherein a single texel can only contain values from adjacent\n      // rows/cols.\n      outData.texShape = texelShape.map(d => d * 2);\n    }\n    if (program.outTexUsage != null) {\n      outData.usage = program.outTexUsage;\n    }\n    if (util.sizeFromShape(output.shape) === 0) {\n      // Short-circuit the computation since the result is empty (has 0 in its\n      // shape).\n      outData.values = util.getTypedArrayFromDType(output.dtype, 0);\n      return output;\n    }\n    const dataToDispose = [];\n    const inputsData = inputs.map(input => {\n      if (input.dtype === 'complex64') {\n        throw new Error(`GPGPUProgram does not support complex64 input. For complex64 ` + `dtypes, please separate the program into real and imaginary ` + `parts.`);\n      }\n      let texData = this.texData.get(input.dataId);\n      if (texData.texture == null) {\n        if (!program.packedInputs && util.sizeFromShape(input.shape) <= env().getNumber('WEBGL_SIZE_UPLOAD_UNIFORM')) {\n          // Upload small tensors that live on the CPU as uniforms, not as\n          // textures. Do this only when the environment supports 32bit floats\n          // due to problems when comparing 16bit floats with 32bit floats.\n          // TODO(https://github.com/tensorflow/tfjs/issues/821): Make it\n          // possible for packed shaders to sample from uniforms.\n          return {\n            shape: input.shape,\n            texData: null,\n            isUniform: true,\n            uniformValues: texData.values\n          };\n        }\n        // This ensures that if a packed program's inputs have not yet been\n        // uploaded to the GPU, they get uploaded as packed right off the bat.\n        if (program.packedInputs) {\n          texData.isPacked = true;\n          texData.shape = input.shape;\n        }\n      }\n      this.uploadToGPU(input.dataId);\n      if (!!texData.isPacked !== !!program.packedInputs) {\n        input = texData.isPacked ? this.unpackTensor(input) : this.packTensor(input);\n        dataToDispose.push(input);\n        texData = this.texData.get(input.dataId);\n      } else if (texData.isPacked && !webgl_util.isReshapeFree(texData.shape, input.shape)) {\n        // This is a special case where a texture exists for a tensor\n        // but the shapes are incompatible (due to packing constraints) because\n        // the tensor did not have a chance to go through the packed reshape\n        // shader. This only happens when we reshape the *same* tensor to form\n        // *distinct* inputs to an op, e.g. dotting a vector with itself. This\n        // case will disappear once packed uploading is the default.\n        const savedInput = input;\n        const targetShape = input.shape;\n        input.shape = texData.shape;\n        input = this.packedReshape(input, targetShape);\n        dataToDispose.push(input);\n        texData = this.texData.get(input.dataId);\n        savedInput.shape = targetShape;\n      }\n      return {\n        shape: input.shape,\n        texData,\n        isUniform: false\n      };\n    });\n    this.uploadToGPU(output.dataId);\n    const outputData = {\n      shape: output.shape,\n      texData: outData,\n      isUniform: false\n    };\n    const key = gpgpu_math.makeShaderKey(program, inputsData, outputData);\n    const binary = this.getAndSaveBinary(key, () => {\n      return gpgpu_math.compileProgram(this.gpgpu, program, inputsData, outputData);\n    });\n    const shouldTimeProgram = this.activeTimers != null;\n    let query;\n    if (shouldTimeProgram) {\n      query = this.startTimer();\n    }\n    if (!env().get('ENGINE_COMPILE_ONLY')) {\n      gpgpu_math.runProgram(this.gpgpu, binary, inputsData, outputData, customUniformValues);\n    }\n    dataToDispose.forEach(info => this.disposeIntermediateTensorInfo(info));\n    if (shouldTimeProgram) {\n      query = this.endTimer(query);\n      this.activeTimers.push({\n        name: program.constructor.name,\n        query: this.getQueryTime(query)\n      });\n    }\n    const glFlushThreshold = env().getNumber('WEBGL_FLUSH_THRESHOLD');\n    // Manually GL flush requested\n    if (glFlushThreshold > 0) {\n      const time = util.now();\n      if (time - this.lastGlFlushTime > glFlushThreshold) {\n        this.gpgpu.gl.flush();\n        this.lastGlFlushTime = time;\n      }\n    }\n    if (!env().getBool('WEBGL_LAZILY_UNPACK') && outData.isPacked && preventEagerUnpackingOfOutput === false) {\n      const unpacked = this.unpackTensor(output);\n      this.disposeIntermediateTensorInfo(output);\n      return unpacked;\n    }\n    return output;\n  }\n  compileAndRun(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput = false) {\n    outputDtype = outputDtype || inputs[0].dtype;\n    const outInfo = this.runWebGLProgram(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput);\n    return outInfo;\n  }\n  getAndSaveBinary(key, getBinary) {\n    if (!(key in this.binaryCache)) {\n      this.binaryCache[key] = getBinary();\n    }\n    return this.binaryCache[key];\n  }\n  getTextureManager() {\n    return this.textureManager;\n  }\n  dispose() {\n    if (this.disposed) {\n      return;\n    }\n    // Avoid disposing the compiled webgl programs during unit testing because\n    // it slows down test execution.\n    if (!env().getBool('IS_TEST')) {\n      const allKeys = Object.keys(this.binaryCache);\n      allKeys.forEach(key => {\n        this.gpgpu.deleteProgram(this.binaryCache[key].webGLProgram);\n        delete this.binaryCache[key];\n      });\n    }\n    this.textureManager.dispose();\n    if (this.canvas != null && typeof HTMLCanvasElement !== 'undefined' && this.canvas instanceof HTMLCanvasElement) {\n      this.canvas.remove();\n    } else {\n      this.canvas = null;\n    }\n    if (this.gpgpuCreatedLocally) {\n      this.gpgpu.program = null;\n      this.gpgpu.dispose();\n    }\n    this.disposed = true;\n  }\n  floatPrecision() {\n    if (this.floatPrecisionValue == null) {\n      this.floatPrecisionValue = tidy(() => {\n        if (!env().get('WEBGL_RENDER_FLOAT32_ENABLED')) {\n          // Momentarily switching DEBUG flag to false so we don't throw an\n          // error trying to upload a small value.\n          const debugFlag = env().getBool('DEBUG');\n          env().set('DEBUG', false);\n          const underflowCheckValue = this.abs(scalar(1e-8)).dataSync()[0];\n          env().set('DEBUG', debugFlag);\n          if (underflowCheckValue > 0) {\n            return 32;\n          }\n        }\n        return 16;\n      });\n    }\n    return this.floatPrecisionValue;\n  }\n  /** Returns the smallest representable number.  */\n  epsilon() {\n    return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n  }\n  uploadToGPU(dataId) {\n    const texData = this.texData.get(dataId);\n    const {\n      shape,\n      dtype,\n      values,\n      texture,\n      usage,\n      isPacked\n    } = texData;\n    if (texture != null) {\n      // Array is already on GPU. No-op.\n      return;\n    }\n    const shouldTimeProgram = this.activeTimers != null;\n    let start;\n    if (shouldTimeProgram) {\n      start = util.now();\n    }\n    let texShape = texData.texShape;\n    if (texShape == null) {\n      // This texShape may not be the final texture shape. For packed or dense\n      // textures, the texShape will be changed when textures are created.\n      texShape = webgl_util.getTextureShapeFromLogicalShape(shape, isPacked);\n      texData.texShape = texShape;\n    }\n    if (values != null) {\n      const shapeAs3D = webgl_util.getShapeAs3D(shape);\n      let program;\n      let width = texShape[1],\n        height = texShape[0];\n      const isByteArray = values instanceof Uint8Array || values instanceof Uint8ClampedArray;\n      // texture for float array is PhysicalTextureType.PACKED_2X2_FLOAT32, we\n      // need to make sure the upload uses the same packed size\n      if (isPacked || !isByteArray) {\n        [width, height] = tex_util.getPackedMatrixTextureShapeWidthHeight(texShape[0], texShape[1]);\n      }\n      if (isPacked) {\n        program = new EncodeMatrixPackedProgram(shapeAs3D, isByteArray);\n      } else {\n        program = new EncodeMatrixProgram(shapeAs3D, isByteArray);\n      }\n      // TexShape for float array needs to be the original shape, which byte\n      // array needs to be packed size. This allow the data upload shape to be\n      // matched with texture creation logic.\n      const tempDenseInputTexShape = isByteArray ? [height, width] : texShape;\n      const tempDenseInputHandle = this.makeTensorInfo(tempDenseInputTexShape, dtype);\n      const tempDenseInputTexData = this.texData.get(tempDenseInputHandle.dataId);\n      if (isByteArray) {\n        tempDenseInputTexData.usage = TextureUsage.PIXELS;\n      } else {\n        tempDenseInputTexData.usage = TextureUsage.UPLOAD;\n      }\n      tempDenseInputTexData.texShape = tempDenseInputTexShape;\n      this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(tempDenseInputHandle.dataId), width, height, values);\n      const customValues = [[height, width]];\n      // We want the output to remain packed regardless of the value of\n      // WEBGL_PACK.\n      const preventEagerUnpacking = true;\n      const encodedOutputTarget = this.runWebGLProgram(program, [tempDenseInputHandle], dtype, customValues, preventEagerUnpacking);\n      // Have the original texture assume the identity of the encoded output.\n      const outputTexData = this.texData.get(encodedOutputTarget.dataId);\n      texData.texShape = outputTexData.texShape;\n      texData.isPacked = outputTexData.isPacked;\n      texData.usage = outputTexData.usage;\n      if (!env().get('ENGINE_COMPILE_ONLY')) {\n        texData.texture = outputTexData.texture;\n        // Once uploaded, don't store the values on cpu.\n        texData.values = null;\n        this.texData.delete(encodedOutputTarget.dataId);\n      } else {\n        this.disposeData(encodedOutputTarget.dataId);\n      }\n      this.disposeIntermediateTensorInfo(tempDenseInputHandle);\n      if (shouldTimeProgram) {\n        this.uploadWaitMs += util.now() - start;\n      }\n    } else {\n      const newTexture = this.acquireTexture(texShape, usage, dtype, isPacked);\n      texData.texture = newTexture;\n    }\n  }\n  convertAndCacheOnCPU(dataId, float32Values) {\n    const texData = this.texData.get(dataId);\n    const {\n      dtype\n    } = texData;\n    if (float32Values != null) {\n      texData.values = float32ToTypedArray(float32Values, dtype);\n    }\n    return texData.values;\n  }\n  acquireTexture(texShape, texType, dtype, isPacked) {\n    this.numBytesInGPU += this.computeBytes(texShape, dtype);\n    if (!this.warnedAboutMemory && this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {\n      const mb = (this.numBytesInGPU / 1024 / 1024).toFixed(2);\n      this.warnedAboutMemory = true;\n      console.warn(`High memory usage in GPU: ${mb} MB, ` + `most likely due to a memory leak`);\n    }\n    return this.textureManager.acquireTexture(texShape, texType, isPacked);\n  }\n  computeBytes(shape, dtype) {\n    return shape[0] * shape[1] * util.bytesPerElement(dtype);\n  }\n  checkCompileCompletion() {\n    for (const [, binary] of Object.entries(this.binaryCache)) {\n      this.checkCompletion_(binary);\n    }\n  }\n  async checkCompileCompletionAsync() {\n    const ps = [];\n    if (this.gpgpu.parallelCompilationExtension) {\n      for (const [, binary] of Object.entries(this.binaryCache)) {\n        ps.push(this.checkCompletionAsync_(binary));\n      }\n      return Promise.all(ps);\n    } else {\n      for (const [, binary] of Object.entries(this.binaryCache)) {\n        const p = new Promise(resolve => {\n          try {\n            this.checkCompletion_(binary);\n            resolve(true);\n          } catch (error) {\n            throw error;\n          }\n        });\n        ps.push(p);\n      }\n      return Promise.all(ps);\n    }\n  }\n  async checkCompletionAsync_(binary) {\n    if (this.gpgpu.gl.getProgramParameter(binary.webGLProgram, this.gpgpu.parallelCompilationExtension.COMPLETION_STATUS_KHR)) {\n      return this.checkCompletion_(binary);\n    } else {\n      await nextFrame();\n      return this.checkCompletionAsync_(binary);\n    }\n  }\n  checkCompletion_(binary) {\n    if (this.gpgpu.gl.getProgramParameter(binary.webGLProgram, this.gpgpu.gl.LINK_STATUS) === false) {\n      console.log(this.gpgpu.gl.getProgramInfoLog(binary.webGLProgram));\n      if (this.gpgpu.gl.getShaderParameter(binary.fragmentShader, this.gpgpu.gl.COMPILE_STATUS) === false) {\n        webgl_util.logShaderSourceAndInfoLog(binary.source, this.gpgpu.gl.getShaderInfoLog(binary.fragmentShader));\n        throw new Error('Failed to compile fragment shader.');\n      }\n      throw new Error('Failed to link vertex and fragment shaders.');\n    }\n    return true;\n  }\n  getUniformLocations() {\n    for (const binary of Object.values(this.binaryCache)) {\n      // TODO: Iterating through all binaries to build VAOs is supposed to be in\n      // a seperate function, like 'setVaos'. However, to avoid breaking changes\n      // for the users using parallel compile feature now, buildVao is silently\n      // added here.\n      this.gpgpu.buildVao(binary.webGLProgram);\n      const {\n        variablesLocations,\n        customUniformLocations,\n        infLoc,\n        nanLoc,\n        outShapeLocation,\n        outShapeStridesLocation,\n        outTexShapeLocation\n      } = getUniformLocations(this.gpgpu, binary.program, binary.webGLProgram);\n      binary.variablesLocations = variablesLocations;\n      binary.customUniformLocations = customUniformLocations;\n      binary.infLoc = infLoc;\n      binary.nanLoc = nanLoc;\n      binary.outShapeLocation = outShapeLocation;\n      binary.outShapeStridesLocation = outShapeStridesLocation;\n      binary.outTexShapeLocation = outTexShapeLocation;\n    }\n  }\n  /**\n   * Create a TF.js tensor out of an existing WebGL texture. A new texture will\n   * be created.\n   */\n  createTensorFromGPUData(values, shape, dtype) {\n    values.channels = values.channels || 'RGBA';\n    const {\n      texture,\n      height,\n      width,\n      channels\n    } = values;\n    const backend = engine().backend;\n    // Have to throw an error, otherwise WebGL just warns and returns wrong\n    // values.\n    if (!backend.gpgpu.gl.isTexture(texture)) {\n      throw new Error(`The texture is invalid. Also, please make sure the texture and ` + `the TFJS WebGL backend are using the same canvas. If you want to ` + `use your own custom canvas, you have to create and use the custom ` + `TFJS WebGL backend created from the canvas through ` + `'new tf.MathBackendWebGL(customCanvas)'.`);\n    }\n    const dataId = backend.writeTexture(texture, shape, dtype, height, width, channels);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, backend);\n  }\n}\nMathBackendWebGL.nextDataId = 0;\nexport { MathBackendWebGL };\nfunction float32ToTypedArray(a, dtype) {\n  if (dtype === 'float32' || dtype === 'complex64') {\n    return a;\n  } else if (dtype === 'int32' || dtype === 'bool') {\n    const result = dtype === 'int32' ? new Int32Array(a.length) : new Uint8Array(a.length);\n    for (let i = 0; i < result.length; ++i) {\n      result[i] = Math.round(a[i]);\n    }\n    return result;\n  } else {\n    throw new Error(`Unknown dtype ${dtype}`);\n  }\n}","map":null,"metadata":{},"sourceType":"module"}